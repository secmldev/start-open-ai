{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fine Tuning LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d14902",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Prompt engineering does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "- fine tuning at least one internal parameter in already pretrained  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "- pre trained GPT3 model to fine tune to chatGPT (GPT-3.5-turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "- GPT3 raw dimond to chatGPT diomand ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "- GPT3 models are trained for word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "- typical completion like this\n",
    "google search like\n",
    "this might be reasonable for gpt3 based on the data it was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b282015",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine tuned model text-davinci-003\n",
    "better response\n",
    "all this may not be perfect, but better than base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt engineering to Fine tuning:\n",
    "Prompt engineering on existing model\n",
    "Many example on existing model, few shot learning.\n",
    "Fine tuning improve on few shot learning by training on many more examples that can fit in few shot learning. Once model is fine tuned, you would not need to give as many example in the prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b4a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28354bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantage of find tuning:\n",
    "Higher quality results than prompting\n",
    "Ability to train on more examples than can fit in a prompt\n",
    "Token savings due to shorter prompts\n",
    "Lower latency requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c211be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fine tuning steps:\n",
    "\n",
    "Prepare and upload training data\n",
    "Train a new fine-tuned model\n",
    "Evaluate results and go back to step 1 if needed\n",
    "Use your fine-tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f5d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d0e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30460b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99993550",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image1.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6ad3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e24fc3",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de366e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d2c92c",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image2_2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec0c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59a28cb2",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image3.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71475b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c29cd8e5",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image4.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc654a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20140154",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image5.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5020d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19270cb",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image6.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf35b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a659c7cc",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image7.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c0a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a61250b",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image8.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f828cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb648c61",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image9.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae10243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1ef01fc",
   "metadata": {},
   "source": [
    "<img src=\"img_fine_tuning/image10.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952dd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41c06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956bce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
