{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba88fb59",
   "metadata": {},
   "source": [
    "[Prompt Examples](https://platform.openai.com/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f513876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ebb4df3",
   "metadata": {},
   "source": [
    "### Grammar Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f3c941",
   "metadata": {},
   "source": [
    "Convert ungrammatical statements into standard English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedcbff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: tqdm in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from openai) (4.59.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/I325907/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (20.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d497224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626bf253",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5ed709523173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   messages=[\n\u001b[1;32m      4\u001b[0m     {\n\u001b[1;32m      5\u001b[0m       \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36m__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_TIMEOUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         requestor = api_requestor.APIRequestor(\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mapi_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    137\u001b[0m     ):\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_base\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         self.api_type = (\n\u001b[1;32m    141\u001b[0m             \u001b[0mApiType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/openai/util.py\u001b[0m in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise openai.error.AuthenticationError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;34m\"No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"She no went to the market.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fc3823",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/Users/I325907/opt/anaconda3/lib/python3.8/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-82c835d0626a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m response = client.chat.completions.create(\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/Users/I325907/opt/anaconda3/lib/python3.8/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"She no went to the market.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1ab9e",
   "metadata": {},
   "source": [
    "### Parse unstructered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94af46",
   "metadata": {},
   "source": [
    "### Calculate time comlexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with Python code, and your task is to calculate its time complexity.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1658919",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98421232",
   "metadata": {},
   "source": [
    "### Python bug fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a piece of Python code, and your task is to find and fix bugs in it.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"import Random\\n    a = random.randint(1,12)\\n    b = random.randint(1,12)\\n    for i in range(10):\\n        question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n        answer = input(question)\\n        if answer = a*b\\n            print (Well done!)\\n        else:\\n            print(\\\"No.\\\")\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1097d74",
   "metadata": {},
   "source": [
    "### Tweet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I loved the new Batman movie!\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543914f",
   "metadata": {},
   "source": [
    "### Mood to color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a description of a mood, and your task is to generate the CSS code for a color that matches it. Write your output in json with a single key called \\\"css_code\\\".\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Blue sky at dusk.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8afcce",
   "metadata": {},
   "source": [
    "### Marv the sarcastic chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How many pounds are in a kilogram?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"This again? There are 2.2 pounds in a kilogram. Please make a note of this.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What does HTML stand for?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"When did the first airplane fly?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish they’d come and take me away.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What time is it?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5183b1",
   "metadata": {},
   "source": [
    "### Interview questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2decef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Create a list of 8 questions for an interview with a science fiction author.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207aec9",
   "metadata": {},
   "source": [
    "### Improve code efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed61ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a piece of Python code, and your task is to provide ideas for efficiency improvements.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"from typing import List\\n                \\n                \\n    def has_sum_k(nums: List[int], k: int) -> bool:\\n        \\\"\\\"\\\"\\n        Returns True if there are two distinct elements in nums such that their sum \\n        is equal to k, and otherwise returns False.\\n        \\\"\\\"\\\"\\n        n = len(nums)\\n        for i in range(n):\\n            for j in range(i+1, n):\\n                if nums[i] + nums[j] == k:\\n                    return True\\n        return False\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fb484",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rap battle writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Write a rap battle between Alan Turing and Claude Shannon.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cd100",
   "metadata": {},
   "source": [
    "### Emoji chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb41412",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a message, and your task is to respond using emojis only.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How are you?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab243f7",
   "metadata": {},
   "source": [
    "### Socratic tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee91f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a Socratic tutor. Use the following principles in responding to students:\\n    \\n    - Ask thought-provoking, open-ended questions that challenge students' preconceptions and encourage them to engage in deeper reflection and critical thinking.\\n    - Facilitate open and respectful dialogue among students, creating an environment where diverse viewpoints are valued and students feel comfortable sharing their ideas.\\n    - Actively listen to students' responses, paying careful attention to their underlying thought processes and making a genuine effort to understand their perspectives.\\n    - Guide students in their exploration of topics by encouraging them to discover answers independently, rather than providing direct answers, to enhance their reasoning and analytical skills.\\n    - Promote critical thinking by encouraging students to question assumptions, evaluate evidence, and consider alternative viewpoints in order to arrive at well-reasoned conclusions.\\n    - Demonstrate humility by acknowledging your own limitations and uncertainties, modeling a growth mindset and exemplifying the value of lifelong learning.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Help me to understand the future of artificial intelligence.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6842",
   "metadata": {},
   "source": [
    "### Meeting notes summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with meeting notes, and your task is to summarize the meeting as follows:\\n    \\n    -Overall summary of discussion\\n    -Action items (what needs to be done and who is doing it)\\n    -If applicable, a list of topics that need to be discussed more fully in the next meeting.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Meeting Date: March 5th, 2050\\n    Meeting Time: 2:00 PM\\n    Location: Conference Room 3B, Intergalactic Headquarters\\n    \\n    Attendees:\\n    - Captain Stardust\\n    - Dr. Quasar\\n    - Lady Nebula\\n    - Sir Supernova\\n    - Ms. Comet\\n    \\n    Meeting called to order by Captain Stardust at 2:05 PM\\n    \\n    1. Introductions and welcome to our newest team member, Ms. Comet\\n    \\n    2. Discussion of our recent mission to Planet Zog\\n    - Captain Stardust: \\\"Overall, a success, but communication with the Zogians was difficult. We need to improve our language skills.\\\"\\n    - Dr. Quasar: \\\"Agreed. I'll start working on a Zogian-English dictionary right away.\\\"\\n    - Lady Nebula: \\\"The Zogian food was out of this world, literally! We should consider having a Zogian food night on the ship.\\\"\\n    \\n    3. Addressing the space pirate issue in Sector 7\\n    - Sir Supernova: \\\"We need a better strategy for dealing with these pirates. They've already plundered three cargo ships this month.\\\"\\n    - Captain Stardust: \\\"I'll speak with Admiral Starbeam about increasing patrols in that area.\\n    - Dr. Quasar: \\\"I've been working on a new cloaking technology that could help our ships avoid detection by the pirates. I'll need a few more weeks to finalize the prototype.\\\"\\n    \\n    4. Review of the annual Intergalactic Bake-Off\\n    - Lady Nebula: \\\"I'm happy to report that our team placed second in the competition! Our Martian Mud Pie was a big hit!\\\"\\n    - Ms. Comet: \\\"Let's aim for first place next year. I have a secret recipe for Jupiter Jello that I think could be a winner.\\\"\\n    \\n    5. Planning for the upcoming charity fundraiser\\n    - Captain Stardust: \\\"We need some creative ideas for our booth at the Intergalactic Charity Bazaar.\\\"\\n    - Sir Supernova: \\\"How about a 'Dunk the Alien' game? We can have people throw water balloons at a volunteer dressed as an alien.\\\"\\n    - Dr. Quasar: \\\"I can set up a 'Name That Star' trivia game with prizes for the winners.\\\"\\n    - Lady Nebula: \\\"Great ideas, everyone. Let's start gathering the supplies and preparing the games.\\\"\\n    \\n    6. Upcoming team-building retreat\\n    - Ms. Comet: \\\"I would like to propose a team-building retreat to the Moon Resort and Spa. It's a great opportunity to bond and relax after our recent missions.\\\"\\n    - Captain Stardust: \\\"Sounds like a fantastic idea. I'll check the budget and see if we can make it happen.\\\"\\n    \\n    7. Next meeting agenda items\\n    - Update on the Zogian-English dictionary (Dr. Quasar)\\n    - Progress report on the cloaking technology (Dr. Quasar)\\n    - Results of increased patrols in Sector 7 (Captain Stardust)\\n    - Final preparations for the Intergalactic Charity Bazaar (All)\\n    \\n    Meeting adjourned at 3:15 PM. Next meeting scheduled for March 19th, 2050 at 2:00 PM in Conference Room 3B, Intergalactic Headquarters.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8c175",
   "metadata": {},
   "source": [
    "### Pro and con discusser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Analyze the pros and cons of remote work vs. office work\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12371878",
   "metadata": {},
   "source": [
    "### Summarize for a 2nd grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Summarize content you are provided with for a second-grade student.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457994d3",
   "metadata": {},
   "source": [
    "### Emoji Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Artificial intelligence is a technology with great promise.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb78d7",
   "metadata": {},
   "source": [
    "### Explain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e01781",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a piece of code, and your task is to explain it in a concise way.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"class Log:\\n        def __init__(self, path):\\n            dirname = os.path.dirname(path)\\n            os.makedirs(dirname, exist_ok=True)\\n            f = open(path, \\\"a+\\\")\\n    \\n            # Check that the file is newline-terminated\\n            size = os.path.getsize(path)\\n            if size > 0:\\n                f.seek(size - 1)\\n                end = f.read(1)\\n                if end != \\\"\\\\n\\\":\\n                    f.write(\\\"\\\\n\\\")\\n            self.f = f\\n            self.path = path\\n    \\n        def log(self, event):\\n            event[\\\"_event_id\\\"] = str(uuid.uuid4())\\n            json.dump(event, self.f)\\n            self.f.write(\\\"\\\\n\\\")\\n    \\n        def state(self):\\n            state = {\\\"complete\\\": set(), \\\"last\\\": None}\\n            for line in open(self.path):\\n                event = json.loads(line)\\n                if event[\\\"type\\\"] == \\\"submit\\\" and event[\\\"success\\\"]:\\n                    state[\\\"complete\\\"].add(event[\\\"id\\\"])\\n                    state[\\\"last\\\"] = event\\n            return state\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb79a1",
   "metadata": {},
   "source": [
    "### Prodcut name generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ada024",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a product description and seed words, and your task is to generate product names.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Product description: A home milkshake maker\\n    Seed words: fast, healthy, compact.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cc1dc",
   "metadata": {},
   "source": [
    "### Spreadsheet creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89dd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Create a two-column CSV of top science fiction movies along with the year of release.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.5,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5cfbe",
   "metadata": {},
   "source": [
    "### Airport code extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad695d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a text, and your task is to extract the airport codes from it.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I want to fly from Orlando to Boston\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ca1bf",
   "metadata": {},
   "source": [
    "### VR fitness idea generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Brainstorm some ideas combining VR and fitness.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.6,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dd71b",
   "metadata": {},
   "source": [
    "### Turn by turn directionm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a text, and your task is to create a numbered list of turn-by-turn directions from it.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Go south on 95 until you hit Sunrise boulevard then take it east to us 1 and head south. Tom Jenkins bbq will be on the left after several miles.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.3,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a06ee2",
   "metadata": {},
   "source": [
    "### Function from specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Write a Python function that takes as input a file path to an image, loads the image into memory as a numpy array, then crops the rows and columns around the perimeter if they are darker than a threshold value. Use the mean value of rows and columns to decide if they should be marked for deletion.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183025d",
   "metadata": {},
   "source": [
    "### Single page web creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce212c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Make a single page website that shows off different neat javascript features for drop-downs and things to display information. The website should be an HTML file with embedded javascript and CSS.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42647366",
   "metadata": {},
   "source": [
    "### Memo writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11178a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Draft a company memo to be distributed to all employees. The memo should cover the following specific points without deviating from the topics mentioned and not writing any fact which is not present here:\\n    \\n    Introduction: Remind employees about the upcoming quarterly review scheduled for the last week of April.\\n    \\n    Performance Metrics: Clearly state the three key performance indicators (KPIs) that will be assessed during the review: sales targets, customer satisfaction (measured by net promoter score), and process efficiency (measured by average project completion time).\\n    \\n    Project Updates: Provide a brief update on the status of the three ongoing company projects:\\n    \\n    a. Project Alpha: 75% complete, expected completion by May 30th.\\n    b. Project Beta: 50% complete, expected completion by June 15th.\\n    c. Project Gamma: 30% complete, expected completion by July 31st.\\n    \\n    Team Recognition: Announce that the Sales Team was the top-performing team of the past quarter and congratulate them for achieving 120% of their target.\\n    \\n    Training Opportunities: Inform employees about the upcoming training workshops that will be held in May, including \\\"Advanced Customer Service\\\" on May 10th and \\\"Project Management Essentials\\\" on May 25th.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88a052",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with a sentence in English, and your task is to translate it into French.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"My name is Jane. What is yours?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e43126",
   "metadata": {},
   "source": [
    "### Natural language to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb519b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Given the following SQL tables, your job is to write queries given a user’s request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628de27",
   "metadata": {},
   "source": [
    "### Review Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be presented with user reviews and your job is to provide a set of tags from the following list. Provide your answer in bullet point form. Choose ONLY from the list of tags provided here (choose either the positive or the negative tag but NOT both):\\n    \\n    - Provides good value for the price OR Costs too much\\n    - Works better than expected OR Did not work as well as expected\\n    - Includes essential features OR Lacks essential features\\n    - Easy to use OR Difficult to use\\n    - High quality and durability OR Poor quality and durability\\n    - Easy and affordable to maintain or repair OR Difficult or costly to maintain or repair\\n    - Easy to transport OR Difficult to transport\\n    - Easy to store OR Difficult to store\\n    - Compatible with other devices or systems OR Not compatible with other devices or systems\\n    - Safe and user-friendly OR Unsafe or hazardous to use\\n    - Excellent customer support OR Poor customer support\\n    - Generous and comprehensive warranty OR Limited or insufficient warranty\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I recently purchased the Inflatotron 2000 airbed for a camping trip and wanted to share my experience with others. Overall, I found the airbed to be a mixed bag with some positives and negatives.\\n    \\n    Starting with the positives, the Inflatotron 2000 is incredibly easy to set up and inflate. It comes with a built-in electric pump that quickly inflates the bed within a few minutes, which is a huge plus for anyone who wants to avoid the hassle of manually pumping up their airbed. The bed is also quite comfortable to sleep on and offers decent support for your back, which is a major plus if you have any issues with back pain.\\n    \\n    On the other hand, I did experience some negatives with the Inflatotron 2000. Firstly, I found that the airbed is not very durable and punctures easily. During my camping trip, the bed got punctured by a stray twig that had fallen on it, which was quite frustrating. Secondly, I noticed that the airbed tends to lose air overnight, which meant that I had to constantly re-inflate it every morning. This was a bit annoying as it disrupted my sleep and made me feel less rested in the morning.\\n    \\n    Another negative point is that the Inflatotron 2000 is quite heavy and bulky, which makes it difficult to transport and store. If you're planning on using this airbed for camping or other outdoor activities, you'll need to have a large enough vehicle to transport it and a decent amount of storage space to store it when not in use.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232056c",
   "metadata": {},
   "source": [
    "### Lesson plan writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Write a lesson plan for an introductory algebra class. The lesson plan should cover the distributive law, in particular how it works in simple cases involving mixes of positive and negative numbers. Come up with some examples that show common student errors.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed52f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60086b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24e7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83724cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032af6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533ae55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
